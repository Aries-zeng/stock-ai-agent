import os
import time
import streamlit as st
import google.generativeai as genai
import yfinance as yf
import pandas as pd

# Try to import akshare, but don't crash the whole app if it's missing
ak = None
ak_import_error = None
try:
    import akshare as ak  # type: ignore
except Exception as e:
    ak = None
    ak_import_error = e

# === æ ¸å¿ƒæ•°æ®å¼•æ“ (æ•´åˆç‰ˆ) ===
@st.cache_data(ttl=3600)
def get_global_financial_data(market, symbol):
    """
    å…¨èƒ½æ•°æ®è·å–å‡½æ•°ï¼šæ”¯æŒ Aè‚¡(AkShare) å’Œ ç¾/æ¸¯/æ—¥è‚¡(YFinance)
    """
    context = ""
    try:
        # --- Aè‚¡é€»è¾‘ (AkShare) ---
        if market == "CN":
            if ak is None:
                return (
                    "âŒ Aè‚¡æ•°æ®æ¥å£æœªèƒ½å¯¼å…¥ (akshare æœªå®‰è£…æˆ–å¯¼å…¥å¤±è´¥)ã€‚\n"
                    f"å¯¼å…¥é”™è¯¯: {ak_import_error}\n"
                    "è§£å†³æ–¹æ³•: åœ¨è¿è¡Œç¯å¢ƒä¸­æ‰§è¡Œ `pip install akshare`ï¼Œç„¶åé‡å¯åº”ç”¨ã€‚\n"
                )
            try:
                stock_spot = ak.stock_zh_a_spot_em()
                target = stock_spot[stock_spot['ä»£ç '].astype(str) == str(symbol)]
                if target.empty:
                    return f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°Aè‚¡ä»£ç  {symbol}ã€‚è¯·æ£€æŸ¥æ˜¯å¦è¾“å…¥æ­£ç¡®ï¼ˆå¦‚ 600519ï¼‰ã€‚"
                row = target.iloc[0]
                name = row.get('åç§°', 'N/A') if hasattr(row, 'get') else row.get('åç§°', 'N/A')
                latest_price = row.get('æœ€æ–°ä»·', 'N/A')
                pct_chg = row.get('æ¶¨è·Œå¹…', 'N/A')
                pe_dynamic = row.get('å¸‚ç›ˆç‡-åŠ¨æ€', 'N/A')
                market_cap = row.get('æ€»å¸‚å€¼', 'N/A')
                context += (
                    f"ã€å®æ—¶è¡Œæƒ…ã€‘\nåç§°ï¼š{name}\nä»·æ ¼ï¼š{latest_price}\næ¶¨è·Œå¹…ï¼š{pct_chg}%\n"
                    f"PE(åŠ¨)ï¼š{pe_dynamic}\nå¸‚å€¼ï¼š{market_cap}\n"
                )
                context += "ã€è´¢åŠ¡æ¦‚å†µã€‘\n(æ³¨ï¼šAè‚¡è¯¦ç»†è´¢åŠ¡æ•°æ®è°ƒç”¨è€—æ—¶è¾ƒé•¿ï¼Œæ­¤å¤„ä»…æä¾›è¡Œæƒ…é©±åŠ¨åˆ†æ)\n"
            except Exception as e:
                return f"Aè‚¡æ•°æ®æ¥å£æŠ¥é”™: {e}"

        else:
            yf_symbol = symbol
            if market == "HK" and not symbol.endswith(".HK"):
                yf_symbol = f"{symbol}.HK"
            elif market == "JP" and not symbol.endswith(".T"):
                yf_symbol = f"{symbol}.T"

            ticker = yf.Ticker(yf_symbol)
            try:
                info = ticker.info or {}
            except Exception:
                info = {}

            current_price = info.get('currentPrice') or info.get('regularMarketPrice')
            if not current_price:
                 return f"âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ°ä»£ç  {yf_symbol} çš„æ•°æ®ã€‚è¯·æ£€æŸ¥ä»£ç æ˜¯å¦æ­£ç¡®ï¼ˆä¾‹å¦‚æ—¥è‚¡éœ€ç¡®è®¤æ˜¯å¦é€€å¸‚æˆ–ä»£ç å˜æ›´ï¼‰ã€‚"

            currency = info.get('currency', 'USD')
            long_name = info.get('longName', symbol)

            context += f"ã€Basic Infoã€‘\nName: {long_name}\nPrice: {current_price} {currency}\n"
            context += f"Market Cap: {info.get('marketCap', 'N/A')}\n"
            context += f"Trailing PE: {info.get('trailingPE', 'N/A')}\n"
            context += f"Forward PE: {info.get('forwardPE', 'N/A')}\n"
            context += f"PB Ratio: {info.get('priceToBook', 'N/A')}\n"
            try:
                roe = info.get('returnOnEquity', 0)
                context += f"ROE: {roe*100:.2f}%\n"
            except Exception:
                context += f"ROE: {info.get('returnOnEquity', 'N/A')}\n"
            try:
                rev_growth = info.get('revenueGrowth', 0)
                context += f"Revenue Growth: {rev_growth*100:.2f}%\n"
            except Exception:
                context += f"Revenue Growth: {info.get('revenueGrowth', 'N/A')}\n"
            context += f"52 Week High: {info.get('fiftyTwoWeekHigh')}\n"
            context += f"Business Summary: {info.get('longBusinessSummary', 'N/A')[:500]}...\n"

    except Exception as e:
        return f"æ•°æ®è·å–å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"

    return context

# ============================
# Helper: call Gemini compatibly across SDK versions
def extract_text_from_response(resp):
    """
    å°è¯•ä»¥å¤šç§å¸¸è§ç»“æ„æå–æ–‡æœ¬å†…å®¹ï¼ˆå…¼å®¹ä¸åŒç‰ˆæœ¬è¿”å›ç»“æ„ï¼‰
    """
    try:
        # direct text attribute
        if hasattr(resp, "text"):
            return getattr(resp, "text")
        # resp.output_text (some helpers)
        if hasattr(resp, "output_text"):
            return getattr(resp, "output_text")
        # resp.last.candidates[*].content / .text
        last = getattr(resp, "last", None)
        if isinstance(last, dict):
            candidates = last.get("candidates", [])
            if candidates:
                cand = candidates[0]
                if isinstance(cand, dict):
                    # candidate content may be text or nested
                    if "content" in cand and isinstance(cand["content"], list):
                        parts = []
                        for p in cand["content"]:
                            if isinstance(p, dict) and p.get("type") == "output_text":
                                parts.append(p.get("text", ""))
                            elif isinstance(p, dict) and "text" in p:
                                parts.append(p.get("text", ""))
                        if parts:
                            return "\n".join(parts)
                    if "text" in cand:
                        return cand.get("text")
                    if "content" in cand and isinstance(cand["content"], str):
                        return cand["content"]
        # resp.output -> list of blocks with content list
        output = getattr(resp, "output", None)
        if isinstance(output, list):
            texts = []
            for o in output:
                if isinstance(o, dict):
                    for c in o.get("content", []):
                        if isinstance(c, dict):
                            if "text" in c:
                                texts.append(c.get("text", ""))
                            elif c.get("type") == "text":
                                texts.append(c.get("text", ""))
            if texts:
                return "\n".join(texts)
        # resp.choices (openai-like)
        choices = getattr(resp, "choices", None)
        if isinstance(choices, (list, tuple)) and len(choices) > 0:
            c0 = choices[0]
            if isinstance(c0, dict):
                # c0 may have message.content
                msg = c0.get("message") or c0.get("text") or c0.get("output")
                if isinstance(msg, dict):
                    # try message.content as string or list
                    content = msg.get("content")
                    if isinstance(content, str):
                        return content
                    if isinstance(content, list):
                        # flatten
                        pieces = []
                        for it in content:
                            if isinstance(it, dict) and "text" in it:
                                pieces.append(it["text"])
                            elif isinstance(it, str):
                                pieces.append(it)
                        if pieces:
                            return "\n".join(pieces)
                elif isinstance(msg, str):
                    return msg
            else:
                # choices items may be objects with message
                msg = getattr(c0, "message", None)
                if msg:
                    content = getattr(msg, "content", None)
                    if isinstance(content, str):
                        return content
        # fallback to string representation
        return str(resp)
    except Exception:
        try:
            return str(resp)
        except Exception:
            return "<æ— æ³•è§£æçš„å“åº”>"

def call_gemini_compat(genai, model_name, system_prompt, prompt, max_output_tokens=800, temperature=0.2):
    """
    é€ä¸ªå°è¯•å¤šç§å¯èƒ½çš„ SDK è°ƒç”¨æ–¹å¼ï¼Œè¿”å› (method_used, text_or_error)
    """
    errors = []
    # 1) genai.generate(...)
    try:
        if hasattr(genai, "generate"):
            resp = genai.generate(model=model_name, prompt=prompt, max_output_tokens=max_output_tokens)
            return ("genai.generate", extract_text_from_response(resp))
    except Exception as e:
        errors.append(("genai.generate", str(e)))
    # 2) genai.chat.completions.create(...)
    try:
        chat_attr = getattr(genai, "chat", None)
        if chat_attr is not None:
            comps = getattr(chat_attr, "completions", None)
            if comps is not None and hasattr(comps, "create"):
                resp = comps.create(
                    model=model_name,
                    messages=[{"role": "system", "content": system_prompt},
                              {"role": "user", "content": prompt}],
                    temperature=temperature,
                    max_output_tokens=max_output_tokens,
                )
                return ("genai.chat.completions.create", extract_text_from_response(resp))
    except Exception as e:
        errors.append(("genai.chat.completions.create", str(e)))
    # 3) genai.text.generate(...)
    try:
        textmod = getattr(genai, "text", None)
        if textmod is not None and hasattr(textmod, "generate"):
            resp = textmod.generate(model=model_name, input=prompt, max_output_tokens=max_output_tokens, temperature=temperature)
            return ("genai.text.generate", extract_text_from_response(resp))
    except Exception as e:
        errors.append(("genai.text.generate", str(e)))
    # 4) genai.responses.create(...)
    try:
        respmod = getattr(genai, "responses", None)
        if respmod is not None and hasattr(respmod, "create"):
            resp = respmod.create(model=model_name, input=prompt, temperature=temperature)
            return ("genai.responses.create", extract_text_from_response(resp))
    except Exception as e:
        errors.append(("genai.responses.create", str(e)))
    # 5) genai.completions.create(...)
    try:
        compmod = getattr(genai, "completions", None)
        if compmod is not None and hasattr(compmod, "create"):
            resp = compmod.create(model=model_name, prompt=prompt, max_tokens=max_output_tokens, temperature=temperature)
            return ("genai.completions.create", extract_text_from_response(resp))
    except Exception as e:
        errors.append(("genai.completions.create", str(e)))

    # If we reach here, nothing worked
    err_msg = " / ".join([f"{m}: {e}" for m, e in errors])
    return ("none", f"All attempts failed. Details: {err_msg}")

# ============================

# 2. é¡µé¢é…ç½®
st.set_page_config(page_title="Global AI Stock Analyst", page_icon="ğŸŒ", layout="centered")

# -------------------------
password_input = st.sidebar.text_input("è¯·è¾“å…¥è®¿é—®å¯†ç  (Password)", type="password", help="è¯·è¾“å…¥è®¿é—®åº”ç”¨çš„å¯†ç ")
if password_input != "zhizunbao":
    if password_input:
        st.sidebar.error("å¯†ç é”™è¯¯ã€‚è‹¥å¿˜è®°å¯†ç ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚")
    else:
        st.sidebar.info("è¯·è¾“å…¥å¯†ç ä»¥è®¿é—®åº”ç”¨ã€‚")
    st.stop()

# 3. ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")

    default_key = "AIzaSyAzgQk7lEfNcsRoCBxRRbjbQR4remrFztM"
    api_key = "AIzaSyAzgQk7lEfNcsRoCBxRRbjbQR4remrFztM" #st.text_input("Gemini API Key", value=default_key, type="password")

    st.divider()
    st.success("ğŸ¤– å½“å‰æ¨¡å‹ï¼šgemini-2.5-flash")
    model_name = "gemini-2.5-flash"

    st.divider()
    st.markdown("""
    **ä»£ç è¾“å…¥æŒ‡å—ï¼š**
    * ğŸ‡ºğŸ‡¸ **ç¾è‚¡**ï¼šç›´æ¥è¾“ä»£ç  (å¦‚ `AAPL`, `NVDA`)
    * ğŸ‡­ğŸ‡° **æ¸¯è‚¡**ï¼šè¾“æ•°å­— (å¦‚ `9988`, `0700`)
    * ğŸ‡¯ğŸ‡µ **æ—¥è‚¡**ï¼šè¾“æ•°å­— (å¦‚ `7203`, `8058`)
    * ğŸ‡¨ğŸ‡³ **Aè‚¡**ï¼šè¾“æ•°å­— (å¦‚ `600519`)
    """)

    if 'search_history' not in st.session_state:
        st.session_state['search_history'] = []

    history_display = list(reversed(st.session_state['search_history']))
    history_options = [""] + history_display
    selected_history = st.selectbox("æœç´¢å†å²ï¼ˆç‚¹å‡»ä»¥å¡«å……ï¼‰", options=history_options, index=0)

    if st.button("æ¸…é™¤æœç´¢å†å²"):
        st.session_state['search_history'] = []
        st.experimental_rerun()

# 4. ä¸»ç•Œé¢
st.title("ğŸŒ å…¨çƒè‚¡å¸‚ AI ç ”æŠ¥ç³»ç»Ÿ")
st.caption("æ”¯æŒï¼šğŸ‡ºğŸ‡¸ ç¾è‚¡ (Nasdaq/NYSE) | ğŸ‡­ğŸ‡° æ¸¯è‚¡ | ğŸ‡¯ğŸ‡µ æ—¥è‚¡ | ğŸ‡¨ğŸ‡³ Aè‚¡")

col1, col2 = st.columns([1, 2])
with col1:
    market_label = st.selectbox(
        "é€‰æ‹©å¸‚åœº",
        [
            "ğŸ‡ºğŸ‡¸ ç¾è‚¡ (US)",
            "ğŸ‡­ğŸ‡° æ¸¯è‚¡ (HK)",
            "ğŸ‡¯è³€ æ—¥è‚¡ (JP)",
            "ğŸ‡¨ğŸ‡³ Aè‚¡ (CN)"
        ],
        index=0
    )
    market_code = market_label.split("(")[1].split(")")[0]

with col2:
    if market_code == "US":
        def_val = "NVDA"
    elif market_code == "HK":
        def_val = "9988"
    elif market_code == "JP":
        def_val = "7203"
    else:
        def_val = "600519"
    prefill = selected_history if selected_history else def_val
    symbol = st.text_input("è¾“å…¥è‚¡ç¥¨ä»£ç ", value=prefill)

SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä½ç²¾é€šå…¨çƒèµ„æœ¬å¸‚åœºçš„é¦–å¸­åˆ†æå¸ˆã€‚è¯·é’ˆå¯¹ç”¨æˆ·æä¾›çš„è‚¡ç¥¨ï¼Œç»“åˆå…¶æ‰€åœ¨å¸‚åœºçš„ç‰¹æ€§ç”Ÿæˆé€»è¾‘æ¸…æ™°çš„ä¸ªè‚¡ç ”æŠ¥ï¼ŒåŒ…å«åŸºæœ¬é¢åˆ†æã€é€»è¾‘éªŒè¯ã€æŠ•èµ„å»ºè®®ã€é£é™©æç¤ºç­‰ã€‚
"""

# 6. æ‰§è¡Œé€»è¾‘
if st.button("ğŸš€ ç”Ÿæˆå…¨çƒç ”æŠ¥", use_container_width=True):
    try:
        if 'search_history' not in st.session_state:
            st.session_state['search_history'] = []

        sym = (symbol or "").strip()
        if sym:
            if sym not in st.session_state['search_history']:
                st.session_state['search_history'].append(sym)
            if len(st.session_state['search_history']) > 50:
                st.session_state['search_history'] = st.session_state['search_history'][-50:]

        with st.spinner("æ­£åœ¨è·å–å¸‚åœºä¸è´¢åŠ¡æ•°æ®..."):
            data_context = get_global_financial_data(market_code, sym)

        st.subheader("åŸå§‹æ•°æ® / Data Context")
        st.text_area("æ•°æ®ä¸Šä¸‹æ–‡ï¼ˆä¾›AIåˆ†æä½¿ç”¨ï¼‰", value=str(data_context), height=260)

        if api_key:
            try:
                # é…ç½® API key
                genai.configure(api_key=api_key)

                # æ„å»º prompt
                prompt = SYSTEM_PROMPT + f"\n\nè‚¡ç¥¨ä»£ç : {sym}\nå¸‚åœº: {market_code}\n\næ•°æ®:\n{data_context}\n\nè¯·åŸºäºä¸Šè¿°æ•°æ®æ’°å†™ä¸€ä»½ç»“æ„åŒ–ç ”æŠ¥ï¼šåŸºæœ¬é¢åˆ†æã€é©±åŠ¨å› ç´ ã€ä¼°å€¼åˆ¤æ–­ã€é£é™©æç¤ºã€‚"

                # ä½¿ç”¨å…¼å®¹è°ƒç”¨å±‚
                method_used, result = call_gemini_compat(genai, model_name, SYSTEM_PROMPT, prompt, max_output_tokens=800, temperature=0.2)

                if method_used == "none":
                    st.error("è°ƒç”¨ Gemini å¤±è´¥ï¼š" + result)
                    # é¢å¤–è¾“å‡ºè¯Šæ–­å»ºè®®
                    st.info("å»ºè®®ï¼šå‡çº§ google-generativeaiï¼ˆpip install --upgrade google-generativeaiï¼‰ï¼Œå¹¶æ£€æŸ¥ genai æ¨¡å—æ”¯æŒçš„å±æ€§ã€‚")
                    st.write("è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼š", result)
                else:
                    st.success(f"è°ƒç”¨æ–¹å¼ï¼š{method_used}")
                    st.subheader("AI ç ”æŠ¥")
                    st.markdown(result)
            except Exception as e:
                st.error(f"è°ƒç”¨ Gemini ç”Ÿæˆç ”æŠ¥æ—¶å‡ºé”™: {e}")
        else:
            st.info("æœªé…ç½® Gemini API Keyï¼Œå·²å±•ç¤ºåŸå§‹æ•°æ®ã€‚")

    except Exception as e:
        st.error(f"å‘ç”Ÿé”™è¯¯: {e}")
